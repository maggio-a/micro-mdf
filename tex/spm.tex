\documentclass[a4paper, 11pt, oneside]{article}

\usepackage[top=3.8cm, bottom=3.5cm, left=3.2cm,  right=3.2cm]{geometry}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}

\usepackage{inconsolata}

\usepackage{pgfplots}
\usepgfplotslibrary{groupplots}
\pgfplotsset{compat=1.12}


\usepackage{subcaption}

\title{{\Large Distributed systems: paradigms and models} \\[3mm] {\LARGE $\mu$MDF: A minimal Macro Data Flow framework} \\[3mm]}
\author{Andrea Maggiordomo \\ \texttt{mggndr89[at]gmail.com}}
\date{2016}

\begin{document}
\maketitle

\section{Introduction}

The project consists in the design and implementation of $\mu$MDF, a parallel framework supporting the execution of Macro Data Flow graphs. The framework is implemented in C++ and relies only on the standard library support for concurrency introduced in the 2011 revision of the language.

\section{Framework overview}

This section covers the design choices made for the project from a user's perspective, and then describes how a $\mu$MDF program can be defined using the framework interface.

\subsection{Features}

From a user perspective, the framework must allow the definition of a Macro Data Flow graph that describes the computation through the dataflow model. This is done by instantiating a \texttt{mdf::Graph} object to which the user can add instruction nodes and connections (where connections link the output of an instruction to the input of another).

The generation of the data that must be processed through the MDF graph is delegated to a \emph{streamer} object that feeds to the graph a stream of input tokens. The input tokens generated by a streamer will trigger one or more fireable instructions in the graph and start the computation on a new graph instance. Streamer objects are implemented as concepts: they are simply objects that define a \texttt{Next()} method with a suitable signature. A MDF graph can have more than one entry point for the data generated by a streamer.

Once the data has flown through the graph, it is processed by a \emph{drainer} object. A drainer is a user defined callable object that is invoked on the output token produced by an interpretation and can perform ``clean-up'' duties. Note that only MDF graphs with exactly one exit point are supported.

A MDF interpreter is an instance of the \texttt{mdf::Mdf<D>} template class, where the template type \texttt{D} is the drainer type. An interpreter is constructed by passing an instance of the MDF graph which will be used as model, the number of workers that the interpreter will use (that is, the parallelism degree of the interpreter), and a \texttt{unique\_ptr} to a drainer type instance. Once the interpreter has been constructed, a user will simply start the interpretation passing a streamer object to the interpreter and waiting for its completion.

\subsection{Graph definition}

A MDF graph is initially defined as empty:
\begin{verbatim}
  mdf::Graph g{};
\end{verbatim}
Once the instance has been constructed, an instruction node can be added by calling the \texttt{AddInstruction} method, a variadic template method which takes as input a callable type, and a list of \texttt{mdf::ParamDecl<T>} objects that tell the framework the type and name of the parameters taken by the function. The type \texttt{T} is used by the framework to cast each token to the correct type, while the parameter names are required in order to forward the output of a node to a specific destination. Supposing we had a function \texttt{int Foo(int,double)}, we could add it to the graph as
\begin{verbatim}
  mdf::NodeId idFoo = g.AddInstruction(
      &Foo, mdf::ParamDecl<int>{"p1Foo"}, mdf::ParamDecl<double>{"p2Foo"});
\end{verbatim}
Note that the order of the parameter types is relevant. The method returns an instruction node identifier which can be used to specify connections. For example, assuming we also had a function \texttt{int Bar(int)}:
\begin{verbatim}
  mdf::NodeId idBar = g.AddInstruction(&Bar, mdf::ParamDecl<int>{"p1Bar"});
  g.Connect(idFoo, idBar, "p1Bar");
\end{verbatim}
would connect the output of \texttt{Foo} -- which is an \texttt{int} -- to the first parameter of \texttt{Bar}.

Another way of connecting two instructions is by declaring a dependency between them. This is useful if an instruction must be executed after another has run because a parameter is modified by side effect. This mechanism can be employed to obtain some degree of data parallelism by passing pointers and declaring dependencies between instruction nodes. The statement
\begin{verbatim}
  g.DeclareDependency(idFoo, idBar);
\end{verbatim}
would instruct the framework to fire \texttt{Bar} only after the execution of \texttt{Foo} has taken place. Dependencies have no name. 

\subsection{Streamer concept}
 
A streamer object must implement a \texttt{Next()} method with the following signature:
\begin{verbatim}
  vector<mdf::InputTokenContainer> Next();
\end{verbatim}
The \texttt{InputTokenContainer} type is used by the framework to assign an input token (that is, a token generated by the streamer) to a macro instruction; it is constructed from a \texttt{mdf::NodeId} and a \texttt{string} (the destination instruction and parameter name), and a \texttt{mdf::TokenHandle} object, which is an erasure type required by the interpreter to handle heterogeneous types. One can obtain a \texttt{TokenHandle} object by wrapping a value \texttt{v} of type \texttt{T} with the helper function \texttt{WrapValue}:
\begin{verbatim}
  auto handle = mdf::WrapValue<T>{v};
\end{verbatim}
As an example, to feed input parameters to the \texttt{Foo} instruction one could do the following:
\begin{verbatim}
  vector<InputTokenContainer> Streamer::Next() {
    vector<InputTokenContainer> input;
    if (!endOfInput()) {
      input.emplace_back(InputTokenContainer{
          idFoo, "p1Foo", mdf::WrapValue<int>(NextInt())});
      input.emplace_back(InputTokenContainer{
          idFoo, "p2Foo", mdf::WrapValue<double>(NextDouble())});
    }
    return input;
  }
\end{verbatim}
By convention returning an empty vector tells the framework that the input stream has no more incoming data.

\subsection{Drainer concept}

A drainer object is simply a callable object that can receive as input a \texttt{TokenHandle} parameter. Any token produced by an instruction node that has no outgoing connections and/or dependencies (\emph{output} nodes) is delivered to the drainer. A MDF graph must have a single output node, but this requirement is not enforced. Accesses to the drainer are protected against race conditions, so it is safe to perform operations on critical resources like writing to a file. Unfortunately, when dealing with an output token, one must downcast explicitly. Suppose we want to drain the output produced by the \texttt{Bar} function:
\begin{verbatim}
  void Drainer::operator()(TokenHandle token) {
    mdf::ValueHandle<int> out = dynamic_pointer_cast<mdf::Value<int>>(token);
    if (out) { 
      int r = out->GetValue();
      // Do something with r
    } else ... // Downcast failed: something is wrong with the graph definition
  }
\end{verbatim}
The \texttt{ValueHandle<T>} type is a pointer type to a \texttt{Value<T>} object, the actual  value container used by the framework.

\subsection{Starting an interpreter}

The MDF interpreter constructor takes as arguments a graph instance, the parallelism degree of the interpreter, and a \texttt{unique\_ptr} to a drainer object:
\begin{verbatim}
  mdf::Mdf<Drainer> interpreter{g, tn, unique_ptr<Drainer>{new Drainer}};
\end{verbatim}
Once the interpreter has been constructed, it is run  by calling the \texttt{Start()} method, passing a unique pointer to a streamer object as parameter (the method is templated on the streamer type):
\begin{verbatim}
  unique_ptr<Streamer> streamer{new Streamer{idFoo}};
  streamer = engine.Start(move(streamer));
\end{verbatim}

The \texttt{Start()} method is blocking, and it returns once the computation has been completed.

\section{The MDF interpreter internals}

This section offers a quick overview of the internal architecture of the MDF interpreter.

\subsection{Graph instancing}

When a streamer generates new input data, a new \texttt{Mdf::GraphHandle} object is constructed in order to keep track of the state of the new graph instance. A \texttt{GraphHandle} object contains an \texttt{instanceId} field, a copy of the original MDF graph and a thread-safe \texttt{mdf::ConcurrentMap} that stores the state of each instruction node in the graph (the tokens available to an instruction, the number of instructions it depends on that have already been executed, and a boolean \texttt{fired} flag). The \texttt{ConcurrentMap} is implemented as a hash table, with bucket-level lock granularity.

\subsection{Task scheduling}

The \texttt{Mdf} interpreter features a global task queue, as well as local queues assigned to each worker thread. When new input is available from the streamer, any instruction that can be immediately fired is scheduled on the global queue; any instruction fired by a worker thread is instead scheduled on its own local queue.

Since a streamer might generate input data at a rate much higher than the one at which the interpretations are performed by the workers, the global queue is bounded in size. If the queue reaches its maximum capacity, the streamer will block until a sufficient amount of tasks have been removed.

Job stealing is employed in an attempt to achieve some kind of load balancing: when a thread can't find any task neither in its local nor in the global queue, it attempts to steal a task from some other thread. Only if it fails in such an attempt it actually yields the execution.

It is worth mentioning that in this case yielding is a rather aggressive strategy, and if the shortage of tasks is prolonged suspending the thread for a brief amount of time could be beneficial to the other busy workers.

\section{Example files}

A few examples are provided in order to show how the framework can be used:
\begin{description}
\item[\texttt{hello.cpp}] The complete implementation of the example used in this document to describe the framework features.
\item[\texttt{sinloops.cpp}] This example instantiates an artificial MDF graph used to test the framework and perform the experiments. The graph contains six nodes that simulate a somewhat expensive computation by iteratively computing the sine of a parameter. The executable takes as argument the number of items streamed, the parallelism degree and the number of iterations performed at each node.
\item[\texttt{mandelbrot.cpp}] This example generates a visual representation of the Mandelbrot set based on the histogram of the number of iterations required to reject each point.
Each pixel coordinate is mapped to a complex number and membership to the Mandelbrot set is rejected up to a fixed number of iterations. The computation is organized as follows: the image is split into a sequence of blocks which are generated by the streamer; each block is further divided into slices, with each slice (composed by a number of block lines) handled by a MDF instruction; since the image generation requires the maximum reached iteration count to map iterations to pixel intensities, each MDF instruction returns the maximum reached iteration, which is then reduced using a ``reverse binary tree'' topology. To avoid dealing with boundary cases, the size of the image is a power of 2 (1024 by 1024), as well as the size of each block (64 by 64) and the number of lines in each slice (4). This means that the MDF graph is composed by an initial stage of 16 macro instructions that compute the iterations, and $\log_2(16)=4$ stages where the maximum number of iterations of the block gets computed by reducing the output of each slice.  The executable file can take the parallelism degree as argument.
\item[\texttt{dependencies.cpp}] This example uses dependencies among nodes (rather than connections) to implement the data parallel computation of a stream of matrix-vector multiplications. The graph declares an array of ``worker'' instructions, and the streamer assigns a slice of the input matrix to each instruction. The executable accepts as input the dimension of the matrix, the number of tasks and the number of items streamed.
\end{description}

Other than these files, the sequential versions of the loops and Mandelbrot examples (\texttt{seq\_sinloops.cpp} and \texttt{seq\_mandelbrot.cpp}) are also provided, as well as the files used to run the experiments (\texttt{*\_exp.cpp}).

Since the framework is implemented as a simple set of header files the samples can be compiled directly at the command line (passing \texttt{-std=c++11} and \texttt{-pthread} as options), otherwise the \texttt{build.sh} and \texttt{build\_mic.sh} scripts can be used:
\begin{description}
\item[\texttt{./build.sh src exe compiler}] builds the source file \texttt{src} with the specified compiler (either \texttt{g++} or \texttt{icpc}) and generates the \texttt{exe} binary.
\item[\texttt{./build\_mic.sh src exe}] uses \texttt{icpc} and compiles with the \texttt{-mmic} flag.
\end{description}

\section{Experimental results}

\pgfplotsset{
  MyGroupStyle/.style={
    width=6.2cm,
    height=5.35cm,
    xlabel={$n$},
    xlabel near ticks,
    ylabel near ticks,
    xlabel style = {yshift=0.5ex },
    ylabel style = {yshift=-0.5ex },
    label style = {
      font = \footnotesize,
    },
    ticklabel style = {
      font = \footnotesize,
    },
    title style = {
      font=\footnotesize,
      yshift = -1.5ex
    },
    max space between ticks=25,
    minor tick num=1,
    xmin=1,
    grid=both,
    every major grid/.style={gray, opacity=0.08},
    every minor grid/.style={gray, opacity=0.15}
  },
  MyCTAxisStyle/.style={
    title={Completion time},
    ymin=0,
    ylabel={Milliseconds},
  },
  MyCTPlotStyle/.style={
    smooth,
    mark=*,
    mark size=1.5pt,
    semithick,
    blue
  },
  MySpAxisStyle/.style={
    title={Speedup},
    ymin=0,
    ylabel={$Speedup(n)$}
  },
  MySpPlotStyle/.style={
    smooth,
    mark=,
    mark size=1.5pt,
    semithick,
    red
  },
  MyScAxisStyle/.style={
    title={Scalability},
    ymin=0,
    ylabel={$Sc(n)$}
  },
  MyScPlotStyle/.style={
    smooth,
    mark=,
    mark size=1.5pt,
    semithick,
    red
  },
  MyEpsAxisStyle/.style={
    title={Efficiency},
    ylabel={$\epsilon(n)$}
  },
  MyEpsPlotStyle/.style={
    smooth,
    mark=,
    mark size=1.5pt,
    semithick,
    red
  }
}

\begin{figure}[p]
\centering
\begin{tikzpicture}
\begin{groupplot}[MyGroupStyle, group style={group size=2 by 2, vertical sep=1.4cm, horizontal sep=2.5cm}, width=6.2cm, height=5.35cm, xmax=60]
\nextgroupplot[MyCTAxisStyle]
\addplot+ [MyCTPlotStyle] table [x=N, y=TN]{mic_sin.table};
\nextgroupplot[MySpAxisStyle]
\addplot+ [smooth, mark=none, semithick, gray] table [x=N, y=N]{mic_sin.table};
\addplot+ [MySpPlotStyle] table [x=N, y expr=(\thisrow{TSEQ} / \thisrow{TN})]{mic_sin.table};
\nextgroupplot[MyScAxisStyle]
\addplot+ [smooth, mark=none, semithick, gray] table [x=N, y=N]{mic_sin.table};
\addplot+ [MyScPlotStyle] table [x=N, y expr=(\thisrow{TONE} / \thisrow{TN})]{mic_sin.table};
\nextgroupplot[MyEpsAxisStyle, ymax=1.019]
\addplot+ [smooth, mark=none, semithick, gray] table [x=N, y expr=1]{mic_sin.table};
\addplot+ [MyEpsPlotStyle] table [x=N, y expr=(\thisrow{TSEQ}/\thisrow{N})*(1/\thisrow{TN}))]{mic_sin.table};
\end{groupplot}
\end{tikzpicture}
\caption{Results for the \texttt{sinloops} test -- Xeon PHI}
\label{sin:mic}
\end{figure}

\begin{figure}[p]
\centering
\begin{tikzpicture}
\begin{groupplot}[MyGroupStyle, group style={group size=2 by 2, vertical sep=1.4cm, horizontal sep=2.5cm}, width=6.2cm, height=5.35cm, xmax=16]
\nextgroupplot[MyCTAxisStyle]
\addplot+ [MyCTPlotStyle] table [x=N, y=TN]{host_sin.table};
\nextgroupplot[MySpAxisStyle]
\addplot+ [smooth, mark=none, semithick, gray] table [x=N, y=N]{host_sin.table};
\addplot+ [MySpPlotStyle] table [x=N, y expr=(\thisrow{TSEQ} / \thisrow{TN})]{host_sin.table};
\nextgroupplot[MyScAxisStyle]
\addplot+ [smooth, mark=none, semithick, gray] table [x=N, y=N]{host_sin.table};
\addplot+ [MyScPlotStyle] table [x=N, y expr=(\thisrow{TONE} / \thisrow{TN})]{host_sin.table};
\nextgroupplot[MyEpsAxisStyle]
\addplot+ [smooth, mark=none, semithick, gray] table [x=N, y expr=1]{host_sin.table};
\addplot+ [MyEpsPlotStyle] table [x=N, y expr=(\thisrow{TSEQ}/\thisrow{N})*(1/\thisrow{TN}))]{host_sin.table};
\end{groupplot}
\end{tikzpicture}
\caption{Results for the \texttt{sinloops} test -- Host machine}
\label{sin:host}
\end{figure}

\begin{figure}[p]
\centering
\begin{tikzpicture}
\begin{groupplot}[MyGroupStyle, group style={group size=2 by 2, vertical sep=1.4cm, horizontal sep=2.5cm}, width=6.2cm, height=5.35cm, xmax=60]
\nextgroupplot[MyCTAxisStyle]
\addplot+ [MyCTPlotStyle] table [x=N, y=TN]{mic_mandel.table};
\nextgroupplot[MySpAxisStyle]
\addplot+ [smooth, mark=none, semithick, gray] table [x=N, y=N]{mic_mandel.table};
\addplot+ [MySpPlotStyle] table [x=N, y expr=(\thisrow{TSEQ} / \thisrow{TN})]{mic_mandel.table};
\nextgroupplot[MyScAxisStyle]
\addplot+ [smooth, mark=none, semithick, gray] table [x=N, y=N]{mic_mandel.table};
\addplot+ [MyScPlotStyle] table [x=N, y expr=(\thisrow{TONE} / \thisrow{TN})]{mic_mandel.table};
\nextgroupplot[MyEpsAxisStyle]
\addplot+ [smooth, mark=none, semithick, gray] table [x=N, y expr=1]{mic_mandel.table};
\addplot+ [MyEpsPlotStyle] table [x=N, y expr=(\thisrow{TSEQ}/\thisrow{N})*(1/\thisrow{TN}))]{mic_mandel.table};
\end{groupplot}
\end{tikzpicture}
\caption{Results for the \texttt{mandelbrot} test -- Xeon PHI}
\label{mandel:mic}
\end{figure}

\begin{figure}[p]
\centering
\begin{tikzpicture}
\begin{groupplot}[MyGroupStyle, group style={group size=2 by 2, vertical sep=1.4cm, horizontal sep=2.5cm}, width=6.2cm, height=5.35cm, xmax=16]
\nextgroupplot[MyCTAxisStyle]
\addplot+ [MyCTPlotStyle] table [x=N, y=TN]{host_mandel.table};
\nextgroupplot[MySpAxisStyle]
\addplot+ [smooth, mark=none, semithick, gray] table [x=N, y=N]{host_mandel.table};
\addplot+ [MySpPlotStyle] table [x=N, y expr=(\thisrow{TSEQ} / \thisrow{TN})]{host_mandel.table};
\nextgroupplot[MyScAxisStyle]
\addplot+ [smooth, mark=none, semithick, gray] table [x=N, y=N]{host_mandel.table};
\addplot+ [MyScPlotStyle] table [x=N, y expr=(\thisrow{TONE} / \thisrow{TN})]{host_mandel.table};
\nextgroupplot[MyEpsAxisStyle]
\addplot+ [smooth, mark=none, semithick, gray] table [x=N, y expr=1]{host_mandel.table};
\addplot+ [MyEpsPlotStyle] table [x=N, y expr=(\thisrow{TSEQ}/\thisrow{N})*(1/\thisrow{TN}))]{host_mandel.table};
\end{groupplot}
\end{tikzpicture}
\caption{Results for the \texttt{mandelbrot} test -- Host machine}
\label{mandel:host}
\end{figure}

The experiments were performed using the \texttt{sinloops} and \texttt{mandelbrot} examples. Each experiment was replicated 10 times, taking the average completion time with a given parallelism degree after discarding the minimum and maximum values measured. The experiments were run both on the Xeon PHI coprocessor and on the host machine.

The \texttt{sinloops} test was performed by streaming 1000 input items and performing 50000 iterations in each node: results for completion time, speedup, scalability and efficiency are reported in figures \ref{sin:mic} and \ref{sin:host}.

The \texttt{mandelbrot} test employed a stream of 256 blocks to generate an image of 1024 by 1024 pixels; experimental results are reported in figures \ref{mandel:mic} and \ref{mandel:host} and do not take into account the time required to write the image file to disk.

The plots show reasonable performance measures for the test that were run on the Xeon PHI coprocessor with good efficiency levels in both applications, while the results were more underwhelming for the tests performed on the host machine.

\section {Conclusions}

This report presented a minimal framework to support the execution of Macro Data Flow graphs, and showed experimental results that seem somewhat encouraging. Possible improvements could be made by performing more strict type checking on the instruction arguments in order to prevent user errors, and more importantly by checking the validity of the graph topology: a simple visit would be enough to detect macroscopic errors like cycles, multiple exit nodes, or instructions that have more incoming edges than the number of parameters they can accept.

\end{document}
